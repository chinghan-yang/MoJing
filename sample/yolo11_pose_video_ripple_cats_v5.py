"""
YOLO11 Pose è¦–è¨ŠèƒŒæ™¯ï¼‹æ¢ä»¶è§¸ç™¼æ°´æ³¢ï¼†è²“å’ªæ·¡å…¥ï¼ˆæ²¿åœ“é‚Šæ—‹è½‰ï¼†è·Ÿéš¨ + å½±ç‰‡é¢¨æ ¼æ°´æ³¢ï¼‰
Python 3.11

æ–°å¢ï¼ˆå°é½Šä¸Šå‚³ Ripple.mp4 çš„è¦–è¦ºé¢¨æ ¼ï¼‰ï¼š
- å°‡æ°´æ³¢æ”¹ç‚º **æŠ˜å°„è®Šå½¢ï¼ˆrefraction displacementï¼‰**ï¼Œä»¥å¾‘å‘æ­£å¼¦æ³¢ + æ™‚é–“/åŠå¾‘è¡°æ¸›æ¨¡æ“¬çœŸå¯¦æ°´é¢ã€‚
- ä»¥ `cv2.remap` åšå€åŸŸåƒç´ ä½ç§»ï¼Œæ”¯æ´å¤šå€‹åŒæ™‚æ³¢ç´‹ï¼Œä¸¦å¯èª¿æ³¢é•·ã€é€Ÿåº¦ã€å¹…åº¦ã€è¡°æ¸›èˆ‡é«˜å…‰å¼·åº¦ã€‚
- ä¿ç•™å…ˆå‰åŠŸèƒ½ï¼šè²“åœ–æ²¿åœ“é‚Šåˆ‡ç·šæ—‹è½‰ï¼†è·Ÿéš¨ã€åŒäººåªè§¸ç™¼ä¸€æ¬¡ã€é›¢é–‹å‰‡è²“æ¶ˆå¤±ã€PNG Alpha æ·¡å…¥ã€åœ“å½¢é®ç½©ã€éª¨æ¶ç–Šåœ–ã€‚

åŸ·è¡Œç¤ºä¾‹ï¼š
  python yolo11_pose_video_ripple_cats_v5.py \
    --bg_video ./calm_water.mp4 \
    --cats ./cat0.png,./cat1.png,./cat2.png,./cat3.png,./cat4.png \
    --cat_size_ratio 0.25 --cat_fade 3.0 --follow_smooth 0.18 \
    --ripple_lambda 24 --ripple_speed 180 --ripple_amp 6 --ripple_radial_decay 0.015 --ripple_time_tau 1.6 --ripple_highlight 0.22 \
    --camera 0 --weights yolo11n-pose.pt --draw_skeleton
"""
from __future__ import annotations
import argparse
import time
import random
import glob
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict

import cv2
import numpy as np
import torch
from ultralytics import YOLO

# COCO 17 é—œéµé»ï¼š0é¼»,1å·¦çœ¼,2å³çœ¼,3å·¦è€³,4å³è€³
FACE_IDXS = [0, 1, 2, 3, 4]

# é€£ç·šï¼ˆéª¨æ¶ï¼‰
COCO_EDGES = [
    (5, 7), (7, 9),    # å·¦è‡‚
    (6, 8), (8, 10),   # å³è‡‚
    (5, 6),            # è‚©é€£ç·š
    (5, 11), (6, 12),  # è‚©åˆ°é«–
    (11, 12),          # é«–é€£ç·š
    (11, 13), (13, 15),# å·¦è…¿
    (12, 14), (14, 16),# å³è…¿
    (0, 1), (0, 2),    # é¼»-çœ¼
    (1, 3), (2, 4)     # çœ¼-è€³
]

# ----------------- æ°´æ³¢ï¼ˆå½±ç‰‡é¢¨æ ¼ï¼‰è³‡æ–™çµæ§‹ -----------------
@dataclass
class Ripple:
    x: float
    y: float
    start: float
    # è¦–è¦ºåƒæ•¸ï¼ˆå¯ç”± CLI æŒ‡å®šé è¨­ï¼‰
    wavelength: float  # åƒç´ ï¼Œæ³¢é•·
    speed: float       # åƒç´ /ç§’ï¼Œç›¸é€Ÿåº¦
    amp: float         # åƒç´ ï¼Œä½ç§»å¹…åº¦
    radial_decay: float  # æ¯åƒç´ çš„å¾‘å‘è¡°æ¸›ä¿‚æ•¸ï¼ˆè¶Šå¤§è¶Šå¿«æ¶ˆå¤±ï¼‰
    time_tau: float      # ç§’ï¼Œæ™‚é–“è¡°æ¸›å¸¸æ•¸ï¼ˆe^-t/tauï¼‰
    highlight: float     # 0~1ï¼Œé«˜å…‰å¼·åº¦

    def alive(self, now: float) -> bool:
        # ç”Ÿå‘½æœŸï¼šç•¶æ™‚é–“è¡°æ¸›å¾ˆå°æˆ–æ“´æ•£éå¤§å°±è¦–ç‚ºçµæŸ
        t = now - self.start
        return t < (self.time_tau * 5.0)

# ----------------- è²“åœ–èˆ‡è¿½è¹¤ -----------------
@dataclass
class CatOverlay:
    base: np.ndarray  # BGRAï¼ˆå·²ç¸®æ”¾ï¼‰
    start: float
    duration: float = 3.0  # æ·¡å…¥ç§’æ•¸
    cx: float = 0.0  # ä»¥åœ–ä¸­å¿ƒå°é½Šçš„æ“ºæ”¾åæ¨™
    cy: float = 0.0
    rot_deg: float = 0.0
    def alpha(self, now: float) -> float:
        a = (now - self.start) / max(1e-6, self.duration)
        return float(np.clip(a, 0.0, 1.0))

@dataclass
class Track:
    id: int
    center: Tuple[float, float]
    last_seen: float
    hold_start: Optional[float] = None
    triggered: bool = False
    cat: Optional[CatOverlay] = None

# ----------------- åƒæ•¸ -----------------

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="YOLO11 Poseï½œå½±ç‰‡èƒŒæ™¯ï¼‹æ°´æ³¢ï¼†è²“æ·¡å…¥ï¼ˆæ—‹è½‰è·Ÿéš¨ + å½±ç‰‡é¢¨æ ¼æ°´æ³¢ï¼‰")
    p.add_argument("--camera", type=int, default=0)
    p.add_argument("--weights", type=str, default="yolo11n-pose.pt")
    p.add_argument("--imgsz", type=int, default=640)
    p.add_argument("--width", type=int, default=1280)
    p.add_argument("--height", type=int, default=720)
    p.add_argument("--circle_ratio", type=float, default=0.95)
    p.add_argument("--conf", type=float, default=0.25)
    p.add_argument("--draw_skeleton", action="store_true")
    p.add_argument("--line_width", type=int, default=2)

    # èƒŒæ™¯èˆ‡è²“
    p.add_argument("--bg_video", type=str, default="./calm_water.mp4")
    p.add_argument("--cats", type=str, default="./cat0.png,./cat1.png,./cat2.png,./cat3.png,./cat4.png")
    p.add_argument("--cat_fade", type=float, default=3.0)
    p.add_argument("--cat_size_ratio", type=float, default=0.25)
    p.add_argument("--follow_smooth", type=float, default=0.18)
    p.add_argument("--rot_offset", type=float, default=30.0)

    # è§¸ç™¼ï¼è¿½è¹¤
    p.add_argument("--face_hold_sec", type=float, default=3.0)
    p.add_argument("--trigger_cooldown", type=float, default=3.0)
    p.add_argument("--match_thresh", type=float, default=100.0)
    p.add_argument("--miss_timeout", type=float, default=1.5)

    # æ°´æ³¢ï¼ˆå½±ç‰‡é¢¨æ ¼ï¼‰
    p.add_argument("--ripple_lambda", type=float, default=24.0)
    p.add_argument("--ripple_speed", type=float, default=180.0)
    p.add_argument("--ripple_amp", type=float, default=6.0)
    p.add_argument("--ripple_radial_decay", type=float, default=0.015)
    p.add_argument("--ripple_time_tau", type=float, default=1.6)
    p.add_argument("--ripple_highlight", type=float, default=0.22)
    return p.parse_args()

# ----------------- å…±ç”¨å·¥å…· -----------------
COCO_EDGES = COCO_EDGES

def create_circular_mask(h: int, w: int, center: Tuple[int, int] | None = None, radius: int | None = None) -> np.ndarray:
    if center is None:
        center = (w // 2, h // 2)
    if radius is None:
        radius = min(h, w) // 2
    Y, X = np.ogrid[:h, :w]
    return (((X - center[0]) ** 2 + (Y - center[1]) ** 2) <= radius ** 2).astype(np.uint8) * 255


def resize_fit(image: np.ndarray, width: int, height: int) -> np.ndarray:
    ih, iw = image.shape[:2]
    scale = max(width / iw, height / ih)
    nw, nh = int(iw * scale), int(ih * scale)
    resized = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_LINEAR)
    x0 = (nw - width) // 2
    y0 = (nh - height) // 2
    return resized[y0:y0 + height, x0:x0 + width]


def extract_kpts(result) -> Tuple[np.ndarray, np.ndarray]:
    if not hasattr(result, "keypoints") or result.keypoints is None:
        return np.zeros((0, 17, 2), dtype=np.float32), np.zeros((0, 17), dtype=np.float32)
    xy = result.keypoints.xy
    conf = getattr(result.keypoints, "conf", None)
    xy = xy.cpu().numpy() if hasattr(xy, "cpu") else np.asarray(xy)
    if conf is None:
        kconf = np.ones((xy.shape[0], xy.shape[1]), dtype=np.float32)
    else:
        kconf = conf.cpu().numpy() if hasattr(conf, "cpu") else np.asarray(conf)
    return xy.astype(np.float32), kconf.astype(np.float32)


def draw_skeletons(canvas: np.ndarray, kpts_xy: np.ndarray, kpts_conf: np.ndarray, lw: int = 2):
    if kpts_xy.size == 0:
        return
    h, w = canvas.shape[:2]
    overlay = canvas.copy()
    for i in range(kpts_xy.shape[0]):
        xy = kpts_xy[i]; cf = kpts_conf[i]
        for a, b in COCO_EDGES:
            if cf[a] > 0.2 and cf[b] > 0.2:
                pa = (int(np.clip(xy[a, 0], 0, w - 1)), int(np.clip(xy[a, 1], 0, h - 1)))
                pb = (int(np.clip(xy[b, 0], 0, w - 1)), int(np.clip(xy[b, 1], 0, h - 1)))
                cv2.line(overlay, pa, pb, (255, 255, 255), lw, cv2.LINE_AA)
        for k in range(xy.shape[0]):
            if cf[k] > 0.2:
                p = (int(np.clip(xy[k, 0], 0, w - 1)), int(np.clip(xy[k, 1], 0, h - 1)))
                cv2.circle(overlay, p, max(1, lw), (255, 255, 255), -1, cv2.LINE_AA)
    cv2.addWeighted(overlay, 0.7, canvas, 0.3, 0, dst=canvas)

# ---------- æ—‹è½‰èˆ‡è²¼åœ–ï¼ˆæ”¯æ´ BGRA Alphaï¼‰ ----------

def ensure_bgra(img: np.ndarray) -> np.ndarray:
    if img.ndim == 3 and img.shape[2] == 4:
        return img
    if img.ndim == 3 and img.shape[2] == 3:
        a = np.full((img.shape[0], img.shape[1], 1), 255, dtype=np.uint8)
        return np.concatenate([img, a], axis=2)
    raise ValueError("Invalid image shape for BGRA conversion")


def rotate_with_alpha(bgra: np.ndarray, angle_deg: float, scale: float = 1.0) -> np.ndarray:
    bgra = ensure_bgra(bgra)
    (h, w) = bgra.shape[:2]
    c = (w / 2.0, h / 2.0)
    M = cv2.getRotationMatrix2D(c, angle_deg, scale)
    cos = abs(M[0, 0]); sin = abs(M[0, 1])
    nw = int((h * sin) + (w * cos))
    nh = int((h * cos) + (w * sin))
    M[0, 2] += (nw / 2) - c[0]
    M[1, 2] += (nh / 2) - c[1]
    rotated = cv2.warpAffine(bgra, M, (nw, nh), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))
    return rotated


def overlay_bgra_center(canvas: np.ndarray, bgra: np.ndarray, cx: int, cy: int, alpha_scale: float):
    if alpha_scale <= 0.0:
        return
    bgra = ensure_bgra(bgra)
    h, w = bgra.shape[:2]
    x0 = int(cx - w // 2); y0 = int(cy - h // 2)
    x1 = max(0, x0); y1 = max(0, y0)
    x2 = min(canvas.shape[1], x0 + w); y2 = min(canvas.shape[0], y0 + h)
    if x1 >= x2 or y1 >= y2: return
    cut = bgra[y1 - y0:y2 - y0, x1 - x0:x2 - x0]
    roi = canvas[y1:y2, x1:x2]
    bgr = cut[:, :, :3].astype(np.float32)
    a = (cut[:, :, 3].astype(np.float32) / 255.0) * alpha_scale
    a = a[..., None]
    out = bgr * a + roi.astype(np.float32) * (1.0 - a)
    canvas[y1:y2, x1:x2] = np.clip(out, 0, 255).astype(np.uint8)

# ---------- å¹¾ä½•å·¥å…· ----------

def nearest_point_on_circle(center: Tuple[int, int], radius: int, p: Tuple[float, float]) -> Tuple[int, int]:
    # æŠŠä»»æ„é» pï¼ˆä¾‹å¦‚é¼»å­åº§æ¨™ï¼‰ã€ŒæŠ•å½±ã€åˆ°ä»¥ center ç‚ºåœ“å¿ƒã€radius ç‚ºåŠå¾‘çš„åœ“å‘¨ä¸Šï¼Œå¾—åˆ°ã€Œåœ“é‚Šä¸Šé›¢ p æœ€è¿‘çš„é»ã€
    cx, cy = center
    vx, vy = p[0] - cx, p[1] - cy # å…ˆç®—å¾åœ“å¿ƒ C(cx,cy) æŒ‡å‘é» P(px,py) çš„å‘é‡ v
    norm = (vx * vx + vy * vy) ** 0.5 # è¨ˆç®—å‘é‡ v çš„é•·åº¦
    if norm < 1e-3: # ç‰¹ä¾‹è™•ç†ï¼šå¦‚æœ P å¹¾ä¹å°±åœ¨åœ“å¿ƒï¼ˆé¿å…é™¤ä»¥ 0ï¼‰ï¼Œå°±é¸æ“‡åœ“å¿ƒå³å´çš„åœ“å‘¨é»ä½œç‚ºé è¨­ï¼ˆ(ğ‘ğ‘¥+ğ‘…,ğ‘ğ‘¦)ï¼‰
        return (cx + radius, cy)
    ux, uy = vx / norm, vy / norm # æŠŠ v æ­£è¦åŒ–æˆå–®ä½å‘é‡ uï¼Œæ–¹å‘ä»æ˜¯ç”±åœ“å¿ƒæŒ‡å‘é» P
    # åœ¨ u çš„æ–¹å‘ä¸Šï¼Œå¾åœ“å¿ƒèµ°ã€ŒåŠå¾‘ã€çš„è·é›¢ï¼Œå¾—åˆ°åœ“å‘¨ä¸Šçš„é» C+Râ‹…uã€‚æœ€å¾Œå››æ¨äº”å…¥æˆæ•´æ•¸åƒç´ åº§æ¨™
    px = int(round(cx + ux * radius))
    py = int(round(cy + uy * radius))
    return px, py


def tangent_angle_deg(center: Tuple[int, int], p: Tuple[int, int], clockwise: bool = True, offset_deg: float = 0.0) -> float:
    # å›å‚³ã€Œåœ“å¿ƒåˆ°é» p çš„åˆ‡ç·šæ–¹å‘è§’åº¦ï¼ˆåº¦æ•¸ï¼‰ã€ï¼›ç”¨ä¾†è®“è²“åœ–æ²¿åœ“é‚Šåˆ‡é½Šåˆ‡ç·šæ—‹è½‰
    cx, cy = center
    rx, ry = p[0] - cx, p[1] - cy # å–å¾—å¾‘å‘å‘é‡ rï¼ˆç”±åœ“å¿ƒæŒ‡å‘é» pï¼‰
    if clockwise: # ç”±å¾‘å‘å‘é‡ r è½‰ 90Â° å¾—åˆ°åˆ‡å‘å‘é‡ tï¼š
        tx, ty = (ry, -rx) # é †æ™‚é‡åˆ‡ç·šï¼š(ry,âˆ’rx)ï¼ˆç­‰æ–¼æŠŠ r æ—‹è½‰ -90Â°ï¼‰
    else:
        tx, ty = (-ry, rx) # é€†æ™‚é‡åˆ‡ç·šï¼š(âˆ’ry,rx)ï¼ˆæŠŠ r æ—‹è½‰ +90Â°ï¼‰
        # äºŒè€…éƒ½èˆ‡ r å‚ç›´ï¼ˆtÂ·r = 0ï¼‰ï¼Œæ–¹å‘åˆ†åˆ¥æ²¿åœ“å‘¨çš„å…©å€‹è½‰å‘

    angle = np.degrees(np.arctan2(ty, tx)) # å–åˆ‡å‘é‡ t çš„æ–¹å‘è§’ï¼ˆä»¥ +x è»¸ç‚º 0Â°ï¼‰ï¼Œç”±å¼§åº¦è½‰æˆåº¦æ•¸
    # å›å‚³è§’åº¦ä¸¦åŠ ä¸Šå¾®èª¿é‡ offset_degï¼ˆç”¨ä¾†æ ¡æ­£ç´ ææœ¬èº«çš„â€œæ­£ä¸Šæ–¹â€å®šç¾©ï¼Œä¾‹å¦‚è¦è®“è²“çš„â€œé ‚ç«¯â€å°é½Šåˆ‡ç·šå¯åŠ  Â±90/180 åšå¾®èª¿ï¼‰
    return float(angle + offset_deg)

# ---------- æ°´æ³¢ï¼ˆå½±ç‰‡é¢¨æ ¼ï¼‰æ ¸å¿ƒï¼šå€åŸŸæŠ˜å°„ä½ç§» ----------

def apply_ripples_refraction(canvas: np.ndarray, ripples: List[Ripple], now: float):
    if not ripples:
        return
    H, W = canvas.shape[:2]
    src = canvas.copy()

    for rp in ripples:
        if not rp.alive(now):
            continue
        t = now - rp.start
        # å½±éŸ¿åŠå¾‘ï¼ˆéš¨æ™‚é–“æ“´æ•£ï¼Œå¤–åŠ  3 å€‹æ³¢é•·è£•åº¦ï¼‰
        R = int(min(max(rp.speed * t + 3 * rp.wavelength, rp.wavelength * 2), max(H, W)))
        x0 = max(0, int(rp.x - R)); y0 = max(0, int(rp.y - R))
        x1 = min(W, int(rp.x + R)); y1 = min(H, int(rp.y + R))
        if x1 - x0 <= 2 or y1 - y0 <= 2:
            continue

        roi = src[y0:y1, x0:x1]
        h, w = roi.shape[:2]
        # åº§æ¨™ç¶²æ ¼ï¼ˆä»¥æ³¢ä¸­å¿ƒç‚ºåŸé»ï¼‰
        xs = np.arange(w, dtype=np.float32); ys = np.arange(h, dtype=np.float32)
        X, Y = np.meshgrid(xs, ys)
        dx = X + x0 - rp.x
        dy = Y + y0 - rp.y
        r = np.sqrt(dx * dx + dy * dy) + 1e-6

        k = 2.0 * np.pi / rp.wavelength
        phase = k * (r - rp.speed * t)  # sin(k r - Ï‰ t)ï¼Œå…¶ä¸­ Ï‰ = k * v
        # ä½ç§»ï¼ˆå¾‘å‘ï¼‰ï¼šå¹…åº¦ Ã— æ­£å¼¦ Ã— è¡°æ¸›ï¼ˆåŠå¾‘èˆ‡æ™‚é–“ï¼‰
        decay = np.exp(-rp.radial_decay * r) * np.exp(-t / rp.time_tau)
        disp = (rp.amp * np.sin(phase) * decay).astype(np.float32)
        ux = (dx / r).astype(np.float32); uy = (dy / r).astype(np.float32)

        map_x = (X + disp * ux).astype(np.float32)
        map_y = (Y + disp * uy).astype(np.float32)

        distorted = cv2.remap(roi, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

        # é«˜å…‰ï¼ˆæ²¿æ³¢å³°ï¼‰ï¼Œæ¨¡æ“¬åå…‰é–ƒçˆ
        if rp.highlight > 1e-3:
            crest = (np.cos(phase) * 0.5 + 0.5) ** 6  # è¶Šæ¥è¿‘æ³¢å³°è¶Šäº®
            crest *= decay
            crest = np.clip(crest * rp.highlight, 0.0, 1.0).astype(np.float32)
            hl = (crest[..., None] * 255.0).astype(np.uint8)
            # ç–ŠåŠ åˆ°äº®åº¦ï¼šè½‰æˆ YUV åšäº®åº¦åŠ æˆè¼ƒè‡ªç„¶
            yuv = cv2.cvtColor(distorted, cv2.COLOR_BGR2YUV)
            yuv[:, :, 0] = np.clip(yuv[:, :, 0].astype(np.int32) + (hl[:, :, 0] // 6), 0, 255).astype(np.uint8)
            distorted = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)

        canvas[y0:y1, x0:x1] = distorted

# ----------------- ä¸»æµç¨‹ -----------------

def main():
    args = parse_args()

    # èƒŒæ™¯å½±ç‰‡
    bgcap = cv2.VideoCapture(args.bg_video)
    if not bgcap.isOpened():
        raise FileNotFoundError(f"ç„¡æ³•é–‹å•ŸèƒŒæ™¯å½±ç‰‡ï¼š{args.bg_video}")

    # æ”å½±æ©Ÿï¼ˆç”¨æ–¼åµæ¸¬ï¼‰
    cam = cv2.VideoCapture(args.camera, cv2.CAP_DSHOW) if cv2.getBuildInformation().find("MSVC") != -1 else cv2.VideoCapture(args.camera)
    cam.set(cv2.CAP_PROP_FRAME_WIDTH, args.width)
    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, args.height)
    if not cam.isOpened():
        raise RuntimeError("ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿã€‚")

    # æ¨¡å‹
    device = "cuda" if torch.cuda.is_available() else "cpu"
    use_half = device.startswith("cuda")
    model = YOLO(args.weights)
    model.to(device)

    # è®€å–è²“åœ–ï¼ˆä¿ç•™ Alphaï¼Œä¸¦å…ˆç¸®æ”¾åˆ°ç›®æ¨™æ¯”ä¾‹ï¼‰
    def discover_cat_paths(cats_arg: str) -> List[str]:
        paths: List[str] = []
        if cats_arg:
            paths.extend([s.strip() for s in cats_arg.split(',') if s.strip()])
        patterns = ["./cats/*.png", "./cats/*.jpg", "./cat*.png", "./cat*.jpg"]
        for pat in patterns:
            for p in glob.glob(pat):
                if p not in paths:
                    paths.append(p)
        return paths

    cat_paths = discover_cat_paths(args.cats)
    raw_cats: List[np.ndarray] = []
    for pth in cat_paths:
        img = cv2.imread(pth, cv2.IMREAD_UNCHANGED)
        if img is not None:
            if img.ndim == 3 and img.shape[2] == 3:
                # æŠŠæ²’æœ‰é€æ˜åº¦é€šé“çš„è²“åœ–ï¼ˆBGRï¼Œ3 é€šé“ï¼‰è½‰æˆå«é€æ˜åº¦çš„ 4 é€šé“ï¼ˆBGRAï¼‰
                a = np.full((img.shape[0], img.shape[1], 1), 255, dtype=np.uint8)
                img = np.concatenate([img, a], axis=2)
            # é ç¸®æ”¾åˆ°æ¯”ä¾‹;æŠŠåŸåœ–å¯¬åº¦ä¹˜ä¸Šç¸®æ”¾æ¯”ä¾‹ï¼Œä¸¦ä¸”ä¸¦è¨­ä¸‹æœ€å° 8 åƒç´ ï¼Œé¿å…æ¯”ä¾‹å¤ªå°é€ æˆ 0 æˆ–éå°å°ºå¯¸
            tw = max(8, int(img.shape[1] * args.cat_size_ratio))
            th = max(8, int(img.shape[0] * args.cat_size_ratio))
            raw_cats.append(cv2.resize(img, (tw, th), interpolation=cv2.INTER_LINEAR))
    cats_loaded = len(raw_cats)

    # ç‹€æ…‹
    prev_t = time.time(); fps = 0.0
    ripples: List[Ripple] = []
    next_track_id = 1
    tracks: Dict[int, Track] = {}
    last_global_trigger: float = 0.0

    win_name = "Video BG + Pose Ripples + Cats (Film-like ripples)"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
    cv2.setWindowProperty(win_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

    while True:
        # èƒŒæ™¯å½±æ ¼å¾ªç’°
        # å˜—è©¦è®€å–ä¸‹ä¸€å¼µèƒŒæ™¯å½±æ ¼ï¼›ok_bg è¡¨ç¤ºæ˜¯å¦æˆåŠŸã€bg_frame æ˜¯å½±æ ¼è³‡æ–™ã€‚
        ok_bg, bg_frame = bgcap.read()
        if not ok_bg or bg_frame is None: # è‹¥è®€ä¸åˆ°ï¼ˆä¾‹å¦‚å½±ç‰‡æ’­åˆ°å°¾ç«¯æˆ–è§£ç¢¼å¤±æ•—ï¼‰ï¼ŒæŠŠæ’­æ”¾ä½ç½®è¨­å›ç¬¬ 0 å¼µå½±æ ¼å†è®€ä¸€æ¬¡ï¼Œé”åˆ°å¾ªç’°æ’­æ”¾çš„æ•ˆæœï¼›è‹¥é‡è®€ä»å¤±æ•—å°±æ‹‹å‡ºéŒ¯èª¤ã€‚
            bgcap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ok_bg, bg_frame = bgcap.read()
            if not ok_bg or bg_frame is None:
                raise RuntimeError("èƒŒæ™¯å½±ç‰‡è®€å–å¤±æ•—ã€‚")
        canvas = resize_fit(bg_frame, args.width, args.height)
        h, w = canvas.shape[:2]

        # åœ“å½¢åƒæ•¸
        diameter = int(min(h, w) * args.circle_ratio)
        radius = diameter // 2
        center = (w // 2, h // 2)

        # æ”å½±æ©Ÿå½±æ ¼
        ok_cam, cam_frame = cam.read()
        if not ok_cam:
            print("è®€å–æ”å½±æ©Ÿå½±åƒå¤±æ•—ï¼Œå˜—è©¦ç¹¼çºŒâ€¦â€¦")
            continue

        # æ¨è«–
        results = model(cam_frame, imgsz=args.imgsz, conf=args.conf, verbose=False, half=use_half)
        res = results[0]
        kxy, kcf = extract_kpts(res)

        # å€™é¸ï¼ˆäº”è‡‰é»ï¼‰
        centers: List[Tuple[float, float]] = [] # æº–å‚™ä¸€Listæ”¾æ¯å€‹äººçš„ä»£è¡¨åº§æ¨™ï¼ˆx, yï¼‰ã€‚å‹åˆ¥è¨»è¨˜è¡¨ç¤ºå…ƒç´ æ˜¯å…©å€‹æµ®é»æ•¸çš„ tuple
        for i in range(kxy.shape[0]): # é€ä¸€èµ°è¨ªé€™ä¸€å¹€åµæ¸¬åˆ°çš„æ¯å€‹äºº
            cf = kcf[i] # å–å‡ºç¬¬ i å€‹äººçš„å„é—œéµé»ä¿¡å¿ƒå€¼ï¼ˆèˆ‡ kxy å°æ‡‰çš„ confidenceï¼‰
            if all(cf[idx] > 0.25 for idx in FACE_IDXS): # åªæœ‰ç•¶æ­¤äººäº”å€‹è‡‰éƒ¨é—œéµé»ï¼ˆé¼»ã€å·¦çœ¼ã€å³çœ¼ã€å·¦è€³ã€å³è€³ï¼‰éƒ½å­˜åœ¨ä¸”ä¿¡å¿ƒå€¼ > 0.25ï¼Œæ‰è¦–ç‚ºæœ‰æ•ˆè‡‰éƒ¨
                centers.append((float(kxy[i, 0, 0]), float(kxy[i, 0, 1])))  # é¼»

        now = time.time()

        # è¿½è¹¤åŒ¹é…
        pair: List[Tuple[float, int, int]] = []
        for tid, tr in tracks.items():
            for j, c in enumerate(centers):
                d = ((tr.center[0]-c[0])**2 + (tr.center[1]-c[1])**2) ** 0.5 # é€ä¸€è¨ˆç®—æ¯å€‹ track ç›®å‰ä¸­å¿ƒ tr.center èˆ‡æœ¬å¹€å€™é¸é¼»å­ centers[j] çš„æ­æ°è·é›¢ d
                if d <= args.match_thresh: # å°æ–¼é–€æª», è¡¨ç¤ºã€Œtrack tid â†” å€™é¸ jã€æ˜¯å¯é…å°çš„å¯èƒ½
                    pair.append((d, tid, j))
        pair.sort(key=lambda x: x[0]) # å°‡ pair ä¾è·é›¢ç”±å°åˆ°å¤§æ’åºï¼Œæº–å‚™åšæœ€çŸ­è·é›¢å„ªå…ˆçš„è²ªå©ªåŒ¹é…
        assigned_t, assigned_c = set(), set() # ç”¨ assigned_t / assigned_c å…©å€‹é›†åˆï¼Œç¢ºä¿ä¸€å€‹ track èˆ‡ä¸€å€‹å€™é¸æœ€å¤šåªæœƒè¢«é…å°ä¸€æ¬¡
        for _, tid, j in pair:
            if tid in assigned_t or j in assigned_c: # ä¾åºèµ°è¨ªæ’åºå¾Œçš„ pairï¼šè‹¥æŸç­†çš„ track æˆ–å€™é¸å·²è¢«é…å°å°±ç•¥éï¼›å¦å‰‡è¦–ç‚ºæˆåŠŸåŒ¹é…ï¼š
                continue
            # æ›´æ–° tr.center = centers[j] èˆ‡ tr.last_seen = nowï¼ˆè¿½è¹¤åˆ°äººã€åˆ·æ–°æ™‚é–“ï¼‰
            tr = tracks[tid]
            tr.center = centers[j]
            tr.last_seen = now
            assigned_t.add(tid); assigned_c.add(j)
            # è‹¥æ˜¯ç¬¬ä¸€æ¬¡çœ‹è¦‹ï¼Œè¨­å®š tr.hold_start = nowï¼Œé–‹å§‹è¨ˆæ™‚ã€Œè‡‰éƒ¨äº”é»é€£çºŒå­˜åœ¨ã€çš„æ™‚é–“
            if tr.hold_start is None:
                tr.hold_start = now

            # ç•¶æ­¤ track å°šæœªè§¸ç™¼ã€ä¸”ã€Œç¾åœ¨ - hold_start â‰¥ face_hold_secã€ï¼ˆé è¨­ 3 ç§’ï¼‰ï¼Œä¸¦ä¸”å…¨åŸŸå†·å» now - last_global_trigger â‰¥ trigger_cooldown ä¹Ÿé€šéæ™‚ï¼š
            if (not tr.triggered) and (now - tr.hold_start >= args.face_hold_sec) and (now - last_global_trigger >= args.trigger_cooldown):
                # å–é¼»å­ä½ç½® (nx, ny)ï¼ˆå¤¾åœ¨ç•«é¢é‚Šç•Œå…§ï¼‰ï¼Œæ–°å¢ä¸€å€‹ Ripple ç‰©ä»¶åˆ° ripplesï¼Œå…¶åƒæ•¸ï¼ˆæ³¢é•·ã€é€Ÿåº¦ã€å¹…åº¦ã€è¡°æ¸›ã€é«˜å…‰ï¼‰éƒ½ä¾†è‡ª CLIã€‚
                nx, ny = tr.center
                nx = int(np.clip(nx, 0, w - 1)); ny = int(np.clip(ny, 0, h - 1))
                # å»ºç«‹ã€Œå½±ç‰‡é¢¨æ ¼ã€æ°´æ³¢
                ripples.append(Ripple(x=nx, y=ny, start=now,
                                      wavelength=args.ripple_lambda,
                                      speed=args.ripple_speed,
                                      amp=args.ripple_amp,
                                      radial_decay=args.ripple_radial_decay,
                                      time_tau=args.ripple_time_tau,
                                      highlight=args.ripple_highlight))
                # è¨­ last_global_trigger = now èˆ‡ tr.triggered = True â†’ åŒä¸€äººåªè§¸ç™¼ä¸€æ¬¡ï¼Œä¸”ç”¨å…¨åŸŸå†·å»é¿å…åŒæ™‚å¤šç™¼
                last_global_trigger = now
                tr.triggered = True
                if cats_loaded > 0: # è‹¥æœ‰è¼‰åˆ°è²“åœ–
                    cat_raw = random.choice(raw_cats) # éš¨æ©ŸæŒ‘ä¸€å¼µç¸®æ”¾å¾Œçš„ cat_raw
                    px, py = nearest_point_on_circle(center, radius - 6, (nx, ny)) # ç”¨ nearest_point_on_circle(...) æ‰¾å‡ºé¼»å­å°åœ“å½¢è¦–çª—é‚Šæ¡†æœ€è¿‘çš„é» (px, py)ã€‚
                    rot = tangent_angle_deg(center, (px, py), clockwise=True, offset_deg=args.rot_offset) # ç”¨ tangent_angle_deg(...) ç®—å‡ºè©²é»çš„åˆ‡ç·šè§’åº¦ï¼ˆè®“è²“åœ–æ²¿åœ“é‚Šæ–¹å‘æ—‹è½‰ï¼‰
                    tr.cat = CatOverlay(base=cat_raw, start=now, duration=max(0.5, args.cat_fade), cx=float(px), cy=float(py), rot_deg=rot) # å»ºç«‹ CatOverlay(...) ä¸¦æ›åˆ° tr.catï¼ˆå«æ·¡å…¥æ™‚é–“ã€åˆå§‹ä½ç½®èˆ‡è§’åº¦ï¼‰

        # æ–°å¢æœªé…å° tracks
        for j, c in enumerate(centers):
            if j in assigned_c:
                continue
            tracks[next_track_id] = Track(id=next_track_id, center=c, last_seen=now, hold_start=now)
            next_track_id += 1

        # ç§»é™¤é›¢é–‹çš„äººï¼ˆè²“éš¨ä¹‹æ¶ˆå¤±ï¼‰
        to_del = []
        for tid, tr in tracks.items():
            if tid in assigned_t:
                continue
            if now - tr.last_seen > args.miss_timeout:
                to_del.append(tid)
        for tid in to_del:
            tracks.pop(tid, None)

        # å¥—ç”¨ã€Œå½±ç‰‡é¢¨æ ¼æ°´æ³¢ã€
        ripples = [rp for rp in ripples if rp.alive(now)]
        apply_ripples_refraction(canvas, ripples, now)

        # éª¨æ¶ï¼ˆå¯é¸ï¼‰
        if args.draw_skeleton:
            draw_skeletons(canvas, kxy, kcf, lw=args.line_width)

        # æ›´æ–°èˆ‡ç¹ªè£½è²“åœ–ï¼ˆæ—‹è½‰ + æ²¿åœ“é‚Šè·Ÿéš¨ï¼‰
        for tid, tr in tracks.items():
            if tr.cat is None:
                continue
            nx, ny = tr.center
            px, py = nearest_point_on_circle(center, radius - 6, (nx, ny))
            a = float(np.clip(args.follow_smooth, 0.0, 1.0))
            tr.cat.cx = tr.cat.cx * (1 - a) + px * a
            tr.cat.cy = tr.cat.cy * (1 - a) + py * a
            tr.cat.rot_deg = tangent_angle_deg(center, (int(tr.cat.cx), int(tr.cat.cy)), clockwise=True, offset_deg=args.rot_offset)
            rotated = rotate_with_alpha(tr.cat.base, tr.cat.rot_deg)
            overlay_bgra_center(canvas, rotated, int(round(tr.cat.cx)), int(round(tr.cat.cy)), tr.cat.alpha(now))

        # åœ“å½¢é®ç½© + é‚Šæ¡†
        mask = create_circular_mask(h, w, center=center, radius=radius)
        masked = cv2.bitwise_and(canvas, canvas, mask=mask)
        cv2.circle(masked, center, radius, (255, 255, 255), 3)

        # FPS
        dt = now - prev_t; prev_t = now
        if dt > 0: fps = 0.9 * fps + 0.1 * (1.0 / dt) if fps > 0 else 1.0 / dt
        cv2.putText(masked, f"FPS:{fps:.1f} Ripples:{len(ripples)} Tracks:{len(tracks)}", (16, 36), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)

        cv2.imshow(win_name, masked)
        if (cv2.waitKey(1) & 0xFF) == ord('q'):
            break

    cam.release(); bgcap.release(); cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
